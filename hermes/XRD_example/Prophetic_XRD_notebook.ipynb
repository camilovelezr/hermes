{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Prophetic XRD Example\n",
    "\n",
    "Here we'll define an example of what Hermes will look like.\n",
    "The particular example we'll consider is autonomously discovering a phase map of a combinitorial wafer from (simulated) 1D X-Ray Diffraction measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the lab-scale diffraction instrument emulator.\n",
    "from Hermes.instruments import XRD_emulator\n",
    "'''Emulates a 1D Diffractometer instrument.'''\n",
    "\n",
    "from Hermes.utils import random_locations\n",
    "'''Chooses random locations to initiallize active learning campaign.'''\n",
    "\n",
    "from Hermes.utils import find_new_locations \n",
    "'''takes in array of locations where we want measurements, \n",
    "and array of measurements, \n",
    "and returns the locations we don't have measurements yet.'''\n",
    "\n",
    "#All the possible sample locations (XY coordinates of the stage where XRD measurments can be taken)\n",
    "# n x 2 array of coordinates [mm]\n",
    "test_locations = XRD_emulator.test_locations\n",
    "\n",
    "#The measurement space (in this example this is the theta-2theta range)\n",
    "# m x 1 array of 2theta positions of the detector [degrees]\n",
    "measurement_space = XRD_emulator.measurement_space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Low level specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum Loops:\n",
    "Loops = 10\n",
    "\n",
    "#Randomly initialize the measurements\n",
    "start_measurements = 5\n",
    "measured_locations = random_locations(test_locations, start_measurements)\n",
    "measurements = np.array([])\n",
    "\n",
    "#Batch size\n",
    "batch_size = 5\n",
    "\n",
    "for i in Loops:\n",
    "    #Find the locations where we want measurements but don't have them yet\n",
    "    new_locations = find_new_locations(measured_locations, measurements)\n",
    "\n",
    "    #Measure those locations.\n",
    "    new_measurements = XRD_emulator.measure(new_locations)\n",
    "\n",
    "    #Append the new measurements to the list of total measurements\n",
    "    measurements = np.concatenate((measurements, new_measurements), axis = 1)\n",
    "\n",
    "    #Cluster the measurments we've taken so far (using thier location information as well)\n",
    "    '''We don't know a piori how many clusters there should be \n",
    "    so we'll need to use a community discovery algorithm. \n",
    "    We're trying to discover a phase diagram, so the clusters should be contigous.'''\n",
    "    clusters, cluster_probabilities = Hermes.ContigousCommunityDiscovery.rb_potts(measured_locations, \n",
    "                                                                                  measurements)\n",
    "\n",
    "    #Classify the whole location space.\n",
    "    '''We can now us a Gaussian Process for Classification to extrapolate \n",
    "    the cluster labels to the rest of the location space.\n",
    "    We know the uncertainty of those labels, so we can use a Heteroscedastic version\n",
    "    to propagate that uncertainty information to the predictions.'''\n",
    "    model = Hermes.Heteroscedastic_GPC.train(measured_locations,\n",
    "                                             clusters, \n",
    "                                             cluster_probabilities)\n",
    "    \n",
    "    (predicted_phase_labels, \n",
    "     predicted_phase_probabilites) =  model.predict(test_locations)\n",
    "\n",
    "    #Choose the next points to measure.\n",
    "    '''Now we can choos the next points to measure based on the pediction uncertainties'''\n",
    "    next_points = batch_acquire(test_locations, \n",
    "                                measured_locations, \n",
    "                                predicted_phase_probabilites\n",
    "                                batch_size)\n",
    "\n",
    "    #Add the next points\n",
    "    measured_locations = np.concatenate((measured_locations, next_points), axis=0)\n",
    "\n",
    "    #Archive the data\n",
    "     #location to save the data to, and the loop index\n",
    "     #extract the hyper-parameters of the model and saving them\n",
    "     #save all the training data, and predictions\n",
    "    archive(save_directory,\n",
    "            i,\n",
    "            model, \n",
    "            measured_locations,\n",
    "            measurements,\n",
    "            clusters, \n",
    "            cluster_probabilities,\n",
    "            predicted_phase_labels,\n",
    "            predicted_phase_probabilites,\n",
    "            next_points)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High level specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hermes\n",
    "\n",
    "instrument = hermes.XRD_emulator\n",
    "\n",
    "# specify how to go from the observations to the predictions\n",
    "data_pipeline = {\n",
    "preprocessing_step\n",
    "clustering_method =  hermes.clustering.some_method\n",
    "classification_method = hermes.classificaition.some_method\n",
    "} \n",
    "#specify how new points will be selected \n",
    "acquistion_method = hermes.acquistion_methods.classification_uncertainty\n",
    "\n",
    "\n",
    "Loops = 10\n",
    "\n",
    "#Wrap the whole active learning loop in a function\n",
    "agent = hermes.active_learining_campaign(instrument, \n",
    "                                            data_pipeline,\n",
    "                                            acquistion_method)\n",
    "#agents and|or instruments have a simpy flag for asychronous execution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API design?\n",
    "\n",
    "- a way to specify optimization variables and search space\n",
    "- a way to specificy instruments and connect them to the optimization variables\n",
    "- a way to specify a model/data reduction pipeline (e.g. XRD phase map estimation)\n",
    "- a way to specify a surrogate model and search strategy\n",
    "\n",
    "what if we have multiple different instruments that are operating asynchronously?\n",
    "What about mixed objective problems where there's a classification task, an optimization task, and a function approximation task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hermes\n",
    "from dataclasses import dataclass\n",
    "\n",
    "samples = hermes.experiment.DiscreteSampleLibrary()\n",
    "xrd_instrument = hermes.xrd.BrukerD8(samples=samples)\n",
    "\n",
    "# specify how to go from the observations to the predictions\n",
    "# function pipeline mapping raw data X -> discrete outputs Y\n",
    "# Y = (background_removal ∘ GaussianMixture ∘ CRF)(X)\n",
    "data_pipeline = DiscreteObservation(\n",
    "    background_removal=hermes.preprocessing.xrd.Chebyshev(order=3, l2_regularization=1e-2),\n",
    "    clustering_method=hermes.GaussianMixture(modes=5),\n",
    "    smoothing_method=hermes.ConditionalRandomField()\n",
    ")\n",
    "\n",
    "aquisition_method = AcquisitionPolicy(\n",
    "    surrogate_model = hermes.GaussianProcessClassifier(),\n",
    "    strategy = hermes.acquistion_methods.ClassificationUncertainty()\n",
    ")\n",
    "\n",
    "search_space = SearchSpace(???)\n",
    "\n",
    "#Wrap the whole active learning loop in a function\n",
    "agent = hermes.ActiveLearningAgent(\n",
    "    instrument, \n",
    "    data_pipeline,\n",
    "    acquistion_method,\n",
    "    search_space,\n",
    ")\n",
    "\n",
    "# start with 5 random observations\n",
    "agent.run(observations=5, batch_size=5, strategy=hermes.acquisition.RandomSearch())\n",
    "\n",
    "# run 50 classification uncertainty experiments in 10 batches of 5\n",
    "agent.run(iterations=10, batch_size=5)\n",
    "\n",
    "# run 10 more experiments one by one\n",
    "# do we want to be able to switch strategies like this?\n",
    "# that would be cool.\n",
    "agent.run(iterations=10, batch_size=1, strategy=hermes.acquisition.PredictiveEntropySearch())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AcquisitionPolicy:\n",
    "    surrogate_model: HermesClassifier\n",
    "    strategy: HermesStrategy\n",
    "    hyperopt_frequency: int = 2\n",
    "\n",
    "#agents and|or instruments have a simpy flag for asychronous execution\n",
    "@dataclass\n",
    "class ActiveLearningAgent():\n",
    "    instrument: HermesInstrument\n",
    "    data_pipeline: HermesDataPipeline\n",
    "    aquisition_policy: AcquisitionPolicy\n",
    "    search_space: SearchSpace\n",
    "\n",
    "    def run(self, max_iterations: int = 10, batch_size: int = 1, strategy: Optional[AcquisitionPolicy] = None):\n",
    "        # fetch data from db\n",
    "        # maybe the search space should keep track of the data?\n",
    "        X = self.instrument.fetch_data()\n",
    "\n",
    "        # fit models\n",
    "        predictive_model = self.data_pipeline.fit(X)\n",
    "\n",
    "        # evaluate acquisition policy\n",
    "        # acquisition policy logs predicted values, model hyperparameters\n",
    "        next_points = self.acquisition_policy(predictive_model, self.optimization_space, queries=batch_size)\n",
    "        \n",
    "        # dispatch experiments\n",
    "        # instrument is responsible for logging data?\n",
    "        self.instrument.measure(next_points)\n",
    "\n",
    "        # await results asynchronously?\n",
    "        # this needs some more thought maybe, we should only re-fit models when an instrument becomes available?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Breakdown of supervised techiques\n",
    "\n",
    "Supervised\n",
    "    Classification\n",
    "        Heteroscedastic\n",
    "            GPC\n",
    "            Random_forests\n",
    "        Homoscedastic\n",
    "            GPC\n",
    "            Random_forests\n",
    "            ImageNet\n",
    "    Regression\n",
    "        Heteroscedastic\n",
    "            GPR\n",
    "        Homoscedastic\n",
    "            GPR\n",
    "            ALLIGN\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
